{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8dc295127c4f4a28a8a13b78022ce6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec7bc20677ba4441a629ec6af1d57e37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_716a88c4f7e9498fb79c40794023b127",
              "IPY_MODEL_788a646aae6f498ab29f309f6d6c9f11"
            ]
          }
        },
        "ec7bc20677ba4441a629ec6af1d57e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "716a88c4f7e9498fb79c40794023b127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d88bf438f4c84fb7b2e6f4335eb80ba9",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 3724301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1039716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af03fa62ebce434398b7c3e38f72c127"
          }
        },
        "788a646aae6f498ab29f309f6d6c9f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8bf86c7730f4d13931b4d3fb7804920",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28% 1039716/3724301 [01:01&lt;02:39, 16808.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a232a1d965049d7b619890f0dbd79a5"
          }
        },
        "d88bf438f4c84fb7b2e6f4335eb80ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af03fa62ebce434398b7c3e38f72c127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8bf86c7730f4d13931b4d3fb7804920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a232a1d965049d7b619890f0dbd79a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b1caee6eaa94486832d3963b265fa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6e9015a0b90484f8d911d9e4cf84cf0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ece11f61476040ab9d2b17d27bc58c3e",
              "IPY_MODEL_398891195001409fa4c543afeec5a82e"
            ]
          }
        },
        "f6e9015a0b90484f8d911d9e4cf84cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ece11f61476040ab9d2b17d27bc58c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8830e63a63e4eef8d4f029a70e17b0a",
            "_dom_classes": [],
            "description": "Making",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 100001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e5c7eb7c27546fab9bad2b799da7592"
          }
        },
        "398891195001409fa4c543afeec5a82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c30720aa36d04543817755e2952ded0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 100001/100001 [00:09&lt;00:00, 10180.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c03a6bc3c194ec085ae3164480ac50a"
          }
        },
        "b8830e63a63e4eef8d4f029a70e17b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e5c7eb7c27546fab9bad2b799da7592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c30720aa36d04543817755e2952ded0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c03a6bc3c194ec085ae3164480ac50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "684d0bd53da8464585ca2718153c7116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dfbee92b558f46368b5021ac09ff2ae2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a23522159434afbae95dff95a2642e7",
              "IPY_MODEL_c745fe33b1974f22ad88c3d89e601311"
            ]
          }
        },
        "dfbee92b558f46368b5021ac09ff2ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a23522159434afbae95dff95a2642e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4939f594ece433cba487426e4f91597",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 239311,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 239311,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46e7639230f24233a4c49719844fdd8f"
          }
        },
        "c745fe33b1974f22ad88c3d89e601311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b3f56d392b2436c857c49d10984e040",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 239311/239311 [00:37&lt;00:00, 6449.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0195a06afe464ff7868ea718edb40c1b"
          }
        },
        "a4939f594ece433cba487426e4f91597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46e7639230f24233a4c49719844fdd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3f56d392b2436c857c49d10984e040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0195a06afe464ff7868ea718edb40c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ2K8q2ZNdYi",
        "colab_type": "text"
      },
      "source": [
        "## GPT 구현 과정\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-26/gpt-model-downstream.png)\n",
        "\n",
        "Transformer를 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zv4p31pOrXz",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCKOY324MSV6",
        "colab_type": "code",
        "outputId": "9db192e0-9b70-4644-9916-bd8b00031734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=c88f24784a61a55cdb8465a6653d8063a394b9f6e13926c5c674e6fecd36e39d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Hd8czWOuVp",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ky6cLBOy3M",
        "colab_type": "code",
        "outputId": "a1955fdf-e349-4653-d63e-3434fb90eb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8hPeW5UO2HS",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5itaeWPKO4sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "# import sentencepiece as spm\n",
        "# import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P-sul-UO9Di",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-a1cEx9PCdS",
        "colab_type": "code",
        "outputId": "c4877602-5ac6-47d0-bcda-d9b741d0ab61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr6iDLT2PB2E",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DaQJYaaPG7T",
        "colab_type": "code",
        "outputId": "ce210a0c-f4ca-4fdd-b912-70264b8b7668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-RlS2ETPMUU",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az2PFmXsPL_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx_KH9T8PSXi",
        "colab_type": "code",
        "outputId": "37888b35-0ccc-4e6f-a170-e4cc20d4e663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAzEdbgfPbSE",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvv4pIYPZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ogsZgK8Pt1O",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Decoder\n",
        "Decoder 입니다.\n",
        "\n",
        "표준 Transformer Decoder에서 Encoder를 사용하지 않기 때문에 Encoder-Decoder Mulit-Head Attention 부분을 제거 하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY6-NBmRP4nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, self_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQDo8rXNP-Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, self_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSNTsw6ySFZ4",
        "colab_type": "text"
      },
      "source": [
        "#### 8. GPT\n",
        "GPT 입니다.\n",
        "\n",
        "단순히 Transformer Decoder를 실행 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voJ4vsHEQEfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" gpt \"\"\"\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, dec_self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4fveNyn3lGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" GPT pretrain \"\"\"\n",
        "class GPTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gpt = GPT(self.config)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab)\n",
        "        logits_lm = self.projection_lm(dec_outputs)\n",
        "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return logits_lm[:, :-1, :].contiguous(), dec_self_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mAaKXoNWr8t",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Pretrain Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJhVouZXW2lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
        "def create_pretrain_instances(doc, n_seq):\n",
        "    # for [BOS], [EOS]\n",
        "    max_seq = n_seq - 2\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i]) # line\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                tokens = []\n",
        "                for chunk in current_chunk: tokens.extend(chunk)\n",
        "                tokens = tokens[:tgt_seq]\n",
        "                if 1 < len(tokens):\n",
        "                    instance = {\n",
        "                        \"tokens\": [\"[BOS]\"] + tokens + [\"[EOS]\"],\n",
        "                    }\n",
        "                    instances.append(instance)\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLrMBAInW76M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터 생성 \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, n_seq):\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    with open(out_file, \"w\") as out_f:\n",
        "        with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "            for i, doc in enumerate(docs):\n",
        "                instances = create_pretrain_instances(doc, n_seq)\n",
        "                for instance in instances:\n",
        "                    out_f.write(json.dumps(instance))\n",
        "                    out_f.write(\"\\n\")\n",
        "                pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erCb80yEXFxs",
        "colab_type": "code",
        "outputId": "f7fb191b-8de0-4036-bced-15207c8ee079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "8dc295127c4f4a28a8a13b78022ce6b3",
            "ec7bc20677ba4441a629ec6af1d57e37",
            "716a88c4f7e9498fb79c40794023b127",
            "788a646aae6f498ab29f309f6d6c9f11",
            "d88bf438f4c84fb7b2e6f4335eb80ba9",
            "af03fa62ebce434398b7c3e38f72c127",
            "a8bf86c7730f4d13931b4d3fb7804920",
            "6a232a1d965049d7b619890f0dbd79a5",
            "4b1caee6eaa94486832d3963b265fa50",
            "f6e9015a0b90484f8d911d9e4cf84cf0",
            "ece11f61476040ab9d2b17d27bc58c3e",
            "398891195001409fa4c543afeec5a82e",
            "b8830e63a63e4eef8d4f029a70e17b0a",
            "9e5c7eb7c27546fab9bad2b799da7592",
            "c30720aa36d04543817755e2952ded0f",
            "4c03a6bc3c194ec085ae3164480ac50a"
          ]
        }
      },
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_gpt.json\"\n",
        "n_seq = 256\n",
        "\n",
        "if not os.path.isfile(out_file):\n",
        "    make_pretrain_data(vocab, in_file, out_file, n_seq)\n",
        "else:\n",
        "    print(f\"{out_file} exists\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc295127c4f4a28a8a13b78022ce6b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=3724301, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b1caee6eaa94486832d3963b265fa50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Making', max=100001, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnFPOOjQvO0q",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Pretrain Data\n",
        "GPT Pretrain Data 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDM8rA-AwjcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터셋 \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "                for i, line in enumerate(f):\n",
        "                    instance = json.loads(line)\n",
        "                    self.sentences.append([vocab.piece_to_id(p) for p in instance[\"tokens\"]])\n",
        "                    pbar.update(1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.sentences[item]), torch.tensor(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oeSF6b7IPhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    dec_inputs, item = list(zip(*inputs))\n",
        "\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        dec_inputs,\n",
        "        torch.stack(item, dim=0),\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSCF-Q-JISzE",
        "colab_type": "code",
        "outputId": "47b98d7e-41e9-43d8-d725-b840cde07efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "684d0bd53da8464585ca2718153c7116",
            "dfbee92b558f46368b5021ac09ff2ae2",
            "9a23522159434afbae95dff95a2642e7",
            "c745fe33b1974f22ad88c3d89e601311",
            "a4939f594ece433cba487426e4f91597",
            "46e7639230f24233a4c49719844fdd8f",
            "9b3f56d392b2436c857c49d10984e040",
            "0195a06afe464ff7868ea718edb40c1b"
          ]
        }
      },
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_gpt.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "684d0bd53da8464585ca2718153c7116",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=239311, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG7wZFuVGp2G",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GdZ7oYmGqZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            dec_inputs, _ = map(lambda v: v.to(config.device), value)\n",
        "            labels_lm = dec_inputs[:, 1:].contiguous()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_lm = outputs[0]\n",
        "\n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "            loss = loss_lm \n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjal3VkSK6rw",
        "colab_type": "code",
        "outputId": "8e043670-5c53-46fe-eb5e-9252c0452619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL8bhIxlGz53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GPTPretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_gpt_pretrain.json\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.gpt.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in trange(n_epoch, desc=\"Epoch\"):\n",
        "    epoch = step + offset\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.gpt.save(epoch, loss, save_pretrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWisHCprMJtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "ef0ba399-1751-46a4-f637-8c63b3180968"
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim((0, 21))\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.050916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.016291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.580410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.262791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.107253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.965728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.836463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.716375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.603737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.494982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.394099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.304632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.229628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.167107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.116405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.074798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6.043476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6.018946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.002548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.994518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss\n",
              "0   20.050916\n",
              "1    9.016291\n",
              "2    7.580410\n",
              "3    7.262791\n",
              "4    7.107253\n",
              "5    6.965728\n",
              "6    6.836463\n",
              "7    6.716375\n",
              "8    6.603737\n",
              "9    6.494982\n",
              "10   6.394099\n",
              "11   6.304632\n",
              "12   6.229628\n",
              "13   6.167107\n",
              "14   6.116405\n",
              "15   6.074798\n",
              "16   6.043476\n",
              "17   6.018946\n",
              "18   6.002548\n",
              "19   5.994518"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEGCAYAAACuBLlKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMI1AAAA0CCEawAAAKBB/j+zQb8jXdQImQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}