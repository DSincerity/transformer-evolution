{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer-02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4StkI_HpXa",
        "colab_type": "text"
      },
      "source": [
        "## Transformer 구현 과정\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/transformer-model-architecture.png)\n",
        "\n",
        "Transformer를 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/2)](https://paul-hyun.github.io/transformer-01/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQGy_iXGIAfi",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCrh7LAHSMi",
        "colab_type": "code",
        "outputId": "4c8d599e-c9b6-44f5-de67-55664df83f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=c38e2bf9e82d5f2f672bebc55586698a076597d6ec19f9aa0c607c1bb3c6c006\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJEj4JnOIHdp",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_muOIjILVC",
        "colab_type": "code",
        "outputId": "afaf4c7a-28b8-46e7-a9c7-9fddad4544c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ATUwUJlIU86",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dquM-bfUIW-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8iGv_HIbQp",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pjohaiGId95",
        "colab_type": "code",
        "outputId": "7e5d8ddc-d2f3-4059-b53b-d1d1304aa746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOhCFxLPIdWx",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69gqsv_IkrL",
        "colab_type": "code",
        "outputId": "d475522b-42ff-4ee5-bac9-6531ce8440af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12ZA0bI6Ip4s",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHGknKGNI9SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3UQU0e8JM0b",
        "colab_type": "code",
        "outputId": "f89a4c8b-6278-4761-e39b-01aa85e5d14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ZAB1PjJv9e",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "이전에 설명된 공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwm_ftQhKHJV",
        "colab_type": "text"
      },
      "source": [
        "###### get_sinusoid_encoding_table\n",
        "Positional Encoding 값을 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWTOw-L8KAV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJRbra2GKjZx",
        "colab_type": "text"
      },
      "source": [
        "###### get_attn_pad_mask\n",
        "Padding Mask를 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNN6p8r6KhzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJbvIXsNjloN",
        "colab_type": "text"
      },
      "source": [
        "###### get_attn_decoder_mask\n",
        "Decoder Mask를 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SegQU2N5jmR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rndBaMj16n",
        "colab_type": "text"
      },
      "source": [
        "###### ScaledDotProductAttention\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/scale_dot_product_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTcmFiLj2ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMLVMjkj7_1",
        "colab_type": "text"
      },
      "source": [
        "###### MultiHeadAttention\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/multi_head_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDPmr4sj8hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1dKmZSkEiV",
        "colab_type": "text"
      },
      "source": [
        "###### PoswiseFeedForwardNet\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/feed-forward.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDahw_QvkE6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQaP14UDkgpV",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Encoder\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/encoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HxrA0mdkoFu",
        "colab_type": "text"
      },
      "source": [
        "###### EncoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0FZFqFkns1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OqU2L7IlDO_",
        "colab_type": "text"
      },
      "source": [
        "###### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRgl12Ekg9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYxaY_hYlYcv",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Decoder\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/decoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Fw0xtJlcyC",
        "colab_type": "text"
      },
      "source": [
        "###### DecoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaQlf1uElb_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVw019y4lkxM",
        "colab_type": "text"
      },
      "source": [
        "###### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d7mwC7clnG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "        # (bs, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
        "\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YevWC1osltnH",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvs28anxl3UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" transformer \"\"\"\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fW_lLz_zONS",
        "colab_type": "text"
      },
      "source": [
        "#### 10. 네이버 영화 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xM6W55dzPrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = Transformer(self.config)\n",
        "        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n",
        "        # (bs, d_hidn)\n",
        "        dec_outputs, _ = torch.max(dec_outputs, dim=1)\n",
        "        # (bs, n_output)\n",
        "        logits = self.projection(dec_outputs)\n",
        "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDx-7ZE-0C64",
        "colab_type": "text"
      },
      "source": [
        "#### 11. 네이버 영화 분류 데이터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hRUATPWRo1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDhfnnWR2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        enc_inputs,\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIJqTZswR_Q5",
        "colab_type": "code",
        "outputId": "1538f143-67bc-4a99-cfbb-773b3e9d90b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_train.json: 100%|██████████| 149995/149995 [00:03<00:00, 46650.61 lines/s]\n",
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_test.json: 100%|██████████| 49997/49997 [00:01<00:00, 49787.53 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI3VfPuVS6s8",
        "colab_type": "text"
      },
      "source": [
        "#### 11. 네이버 영화 분류 데이터 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewCUJDHTJjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "            _, indices = logits.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc9AcaiYTKK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            loss_val = loss.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PrcR_qTs3G",
        "colab_type": "code",
        "outputId": "cdfd46d3-6406-4409-e2fa-68293094f126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mATLq-JjUAa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_epoch, best_loss, best_score = 0, 0, 0\n",
        "losses, scores = [], []\n",
        "for epoch in range(n_epoch):\n",
        "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
        "    score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "    losses.append(loss)\n",
        "    scores.append(score)\n",
        "\n",
        "    if best_score < score:\n",
        "        best_epoch, best_loss, best_score = epoch, loss, score\n",
        "print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0WVadcVJr58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "d550ac37-9996-41af-9743-208dc593eeb4"
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses,\n",
        "    \"score\": scores\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.plot(losses)\n",
        "plt.plot(scores)\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, n_epoch - 1))\n",
        "plt.ylabel('Position')\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.482965</td>\n",
              "      <td>0.803348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.404563</td>\n",
              "      <td>0.808489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.377611</td>\n",
              "      <td>0.819709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.356547</td>\n",
              "      <td>0.820049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.335104</td>\n",
              "      <td>0.829430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.314536</td>\n",
              "      <td>0.829670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.293207</td>\n",
              "      <td>0.832370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.270358</td>\n",
              "      <td>0.822509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.245801</td>\n",
              "      <td>0.828670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.224932</td>\n",
              "      <td>0.834970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss     score\n",
              "0  0.482965  0.803348\n",
              "1  0.404563  0.808489\n",
              "2  0.377611  0.819709\n",
              "3  0.356547  0.820049\n",
              "4  0.335104  0.829430\n",
              "5  0.314536  0.829670\n",
              "6  0.293207  0.832370\n",
              "7  0.270358  0.822509\n",
              "8  0.245801  0.828670\n",
              "9  0.224932  0.834970"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAEGCAYAAACTjGeYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBCjQRUREIkCBLiIiEgEKdBERkQj4/6QljKZrhFIhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}